{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own code to fit a logistic regression model to the data set described below in a pro- gramming language of your choice. (**IMPORTANT: DO NOT USE ANY IN-BUILT LIBRARIES**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of Data Set 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set describes the operating conditions of a reactor and contains class labels about whether the reactor will operate or fail under those operating conditions. Your job is to construct a logistic regression model to predict the same.\n",
    "\n",
    " - **q1_data_matrix.csv**: This file contains a 1000 × 5 data matrix. The 5 features are the operating conditions of the reactor; their corresponding ranges are described below:\n",
    " \n",
    "    1. **Temperature:** 400-700 K\n",
    "    2. **Pressure:** 1-50 bar\n",
    "    3. **Feed Flow Rate:** 50-200 kmol/hr\n",
    "    4. **Coolant Flow Rate:** 1000-3600 L/hr\n",
    "    5. **Inlet Reactant Concentration:** 0.1-0.5 mol fraction\n",
    "    \n",
    "    \n",
    " - **q1_labels.csv**: This file contains a 1000 × 1 vector of 0/1 labels for whether the reactor will operate or fail under the corresponding operating conditions.\n",
    "     <br><br>\n",
    "     \n",
    "     -  0: The reactor will operate well under the operating conditions\n",
    "     -  1: The reactor fails under the operating conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some General Guidelines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Partition your data into a training set and a test set. Keep **70%** of your data for **training** and set aside the remaining **30%** for **testing.**\n",
    "2. Fit a logistic regression model on the training set. Choose an appropriate objective function to quantify classification error. **Manually code for the gradient descent procedure** used to find optimum model parameters. (**Note:** You may need to perform multiple initializations to avoid local minima)\n",
    "3. Evaluate the performance of above model on your test data. Report the **confusion matrix** and the F1 **Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Use `pandas.read_csv` method to load data and label the columns accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/q1_data_matrix.csv', header=None, names=['temp', 'press', 'ffr', 'cfr', 'irc'])\n",
    "labels = pd.read_csv('../data/q1_labels.csv', header=None, names=['oper'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Have a look on the first few rows using `pandas.DataFrame.head` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>ffr</th>\n",
       "      <th>cfr</th>\n",
       "      <th>irc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406.86</td>\n",
       "      <td>17.66</td>\n",
       "      <td>121.83</td>\n",
       "      <td>2109.20</td>\n",
       "      <td>0.1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693.39</td>\n",
       "      <td>24.66</td>\n",
       "      <td>133.18</td>\n",
       "      <td>3138.96</td>\n",
       "      <td>0.3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>523.10</td>\n",
       "      <td>23.23</td>\n",
       "      <td>146.55</td>\n",
       "      <td>1058.24</td>\n",
       "      <td>0.4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>612.86</td>\n",
       "      <td>40.97</td>\n",
       "      <td>94.44</td>\n",
       "      <td>1325.12</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.28</td>\n",
       "      <td>37.44</td>\n",
       "      <td>185.48</td>\n",
       "      <td>2474.51</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     temp  press     ffr      cfr     irc\n",
       "0  406.86  17.66  121.83  2109.20  0.1033\n",
       "1  693.39  24.66  133.18  3138.96  0.3785\n",
       "2  523.10  23.23  146.55  1058.24  0.4799\n",
       "3  612.86  40.97   94.44  1325.12  0.3147\n",
       "4  500.28  37.44  185.48  2474.51  0.2284"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   oper\n",
       "0   0.0\n",
       "1   0.0\n",
       "2   1.0\n",
       "3   1.0\n",
       "4   0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features are real numbers so no encoding required.\n",
    "<br>\n",
    "Get the number of samples using `pandas.DataFrame.shape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number is just 1000 no need to use batch or stochastic methods for gradient descent.\n",
    "<br>\n",
    "Use `pandas.DataFrame.isnull` & `pandas.DataFrame.sum` together to get the count of rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp     0\n",
       "press    0\n",
       "ffr      0\n",
       "cfr      0\n",
       "irc      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in the data. No need to drop any rows.\n",
    "<br>\n",
    "Find the distribution of samples across two classes using `pandas.Series.value_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    585\n",
       "1.0    415\n",
       "Name: oper, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"oper\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples are almost equally distributed across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>ffr</th>\n",
       "      <th>cfr</th>\n",
       "      <th>irc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oper</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>546.150291</td>\n",
       "      <td>24.906256</td>\n",
       "      <td>121.623419</td>\n",
       "      <td>2785.807744</td>\n",
       "      <td>0.303489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>547.634964</td>\n",
       "      <td>26.320747</td>\n",
       "      <td>129.829783</td>\n",
       "      <td>1605.060819</td>\n",
       "      <td>0.301568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temp      press         ffr          cfr       irc\n",
       "oper                                                          \n",
       "0.0   546.150291  24.906256  121.623419  2785.807744  0.303489\n",
       "1.0   547.634964  26.320747  129.829783  1605.060819  0.301568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([features, labels[\"oper\"]], axis=1).groupby(\"oper\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average *Coolant Flow Rate* is very less for `oper=1` while every other parameter averages are almost same for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test, 70% and 30% respectively using `numpy.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_X, test_X] = np.split(features, [int(0.7*features.shape[0])], axis=0)\n",
    "[train_Y, test_Y] = np.split(labels, [int(0.7*labels.shape[0])], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of samples across the classes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    398\n",
       "1.0    302\n",
       "Name: oper, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[\"oper\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract every feature by corresponding mean and divide by corresponding standard deviation. Use `pandas.DataFrame.mean` and `pandas.DataFrame.std` for mean and standard deviation respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>ffr</th>\n",
       "      <th>cfr</th>\n",
       "      <th>irc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.598642</td>\n",
       "      <td>-0.534905</td>\n",
       "      <td>-0.063694</td>\n",
       "      <td>-0.207417</td>\n",
       "      <td>-1.705472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.685504</td>\n",
       "      <td>-0.044677</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>1.142378</td>\n",
       "      <td>0.689765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.266323</td>\n",
       "      <td>-0.144823</td>\n",
       "      <td>0.512715</td>\n",
       "      <td>-1.585001</td>\n",
       "      <td>1.572312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762487</td>\n",
       "      <td>1.097555</td>\n",
       "      <td>-0.702361</td>\n",
       "      <td>-1.235179</td>\n",
       "      <td>0.134473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.527881</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>1.420466</td>\n",
       "      <td>0.271426</td>\n",
       "      <td>-0.616649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp     press       ffr       cfr       irc\n",
       "0 -1.598642 -0.534905 -0.063694 -0.207417 -1.705472\n",
       "1  1.685504 -0.044677  0.200960  1.142378  0.689765\n",
       "2 -0.266323 -0.144823  0.512715 -1.585001  1.572312\n",
       "3  0.762487  1.097555 -0.702361 -1.235179  0.134473\n",
       "4 -0.527881  0.850340  1.420466  0.271426 -0.616649"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (train_X-train_X.mean())/train_X.std()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column of all ones to train_X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>ffr</th>\n",
       "      <th>cfr</th>\n",
       "      <th>irc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.598642</td>\n",
       "      <td>-0.534905</td>\n",
       "      <td>-0.063694</td>\n",
       "      <td>-0.207417</td>\n",
       "      <td>-1.705472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.685504</td>\n",
       "      <td>-0.044677</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>1.142378</td>\n",
       "      <td>0.689765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.266323</td>\n",
       "      <td>-0.144823</td>\n",
       "      <td>0.512715</td>\n",
       "      <td>-1.585001</td>\n",
       "      <td>1.572312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.762487</td>\n",
       "      <td>1.097555</td>\n",
       "      <td>-0.702361</td>\n",
       "      <td>-1.235179</td>\n",
       "      <td>0.134473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.527881</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>1.420466</td>\n",
       "      <td>0.271426</td>\n",
       "      <td>-0.616649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias      temp     press       ffr       cfr       irc\n",
       "0     1 -1.598642 -0.534905 -0.063694 -0.207417 -1.705472\n",
       "1     1  1.685504 -0.044677  0.200960  1.142378  0.689765\n",
       "2     1 -0.266323 -0.144823  0.512715 -1.585001  1.572312\n",
       "3     1  0.762487  1.097555 -0.702361 -1.235179  0.134473\n",
       "4     1 -0.527881  0.850340  1.420466  0.271426 -0.616649"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.insert(0, 'bias', 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `sigmoid` that computes sigmoid of input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `cost` that computes loss given prediction and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(probability, label):\n",
    "    return (-label*np.log(probability)-(1-label)*np.log(1-probability)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `gradient` function that computes gradient with respect to each parameter given features, labels and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(features, parameters, labels):\n",
    "    h = sigmoid(np.dot(features, parameters))\n",
    "    return np.dot(features.transpose(), h-labels)/labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gradient_descent` function that performs iterations of gradient descent and returns parameters given features, labels, learning rate and number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, labels, learning_rate, number_of_iterations):\n",
    "    parameters = np.random.normal(0, 1, features.shape[1])\n",
    "    for i in range(number_of_iterations):\n",
    "        grad = gradient(features, parameters, labels)\n",
    "        parameters -= learning_rate*grad\n",
    "        '''print(i+1, cost(sigmoid(np.dot(features, parameters)), labels), grad)'''\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict` function that returns the predicted labels given features, parameters and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, parameters, threshold):\n",
    "    return sigmoid(np.dot(features, parameters)) >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`misclassification_error` function returns misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_error(predictions, labels):\n",
    "    return (predictions!=labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `gradient_descent` and print cost and gradient at each iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06428571428571428\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "Y = train_Y.iloc[:, 0]\n",
    "theta = gradient_descent(X, Y, 0.01, 1500)\n",
    "print(misclassification_error(predict(X, theta, 0.5), Y))\n",
    "X_t = (test_X-test_X.mean())/test_X.std()\n",
    "X_t.insert(0, 'bias', 1)\n",
    "Y_t = test_Y.iloc[:, 0]\n",
    "print(misclassification_error(predict(X_t, theta, 0.5), Y_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform iterations of `gradient_descent` with multiple initialization and print misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0614 0.1067 [-0.48669393  0.00700717  0.42314132  0.17960628 -2.20864394  0.20135226]\n",
      "2 0.0743 0.1133 [-0.35615802  0.08905102  0.30049108  0.35165182 -1.98849167  0.01629144]\n",
      "3 0.0657 0.1267 [-0.36246268  0.16738791  0.42733766  0.19111541 -1.89718749 -0.02118091]\n",
      "4 0.0543 0.09 [-0.56482636  0.10096672  0.31344391  0.4071495  -2.19584181  0.12585575]\n",
      "5 0.0743 0.1133 [-0.45949211  0.2087388   0.32651188  0.46893444 -2.26295203  0.17071384]\n",
      "6 0.0643 0.1 [-5.19511783e-01 -5.65543215e-05  3.16389908e-01  3.60090242e-01\n",
      " -2.16593152e+00 -4.68847475e-02]\n",
      "7 0.0543 0.1033 [-0.45871588  0.15515207  0.33834754  0.2379893  -1.92682627  0.02405955]\n",
      "8 0.0629 0.1167 [-0.44426825  0.23178596  0.40359731  0.29411205 -1.96157201  0.02820587]\n",
      "9 0.0943 0.1333 [-0.23623519 -0.03492256  0.41872851  0.35162414 -2.03271458 -0.04669111]\n",
      "10 0.0671 0.0967 [-0.76798016  0.33876889  0.37694651  0.46298355 -2.46983007 -0.17594117]\n",
      "11 0.0843 0.1267 [-0.33044129 -0.08065153  0.25199863  0.15918316 -1.97258216  0.0983956 ]\n",
      "12 0.0557 0.1 [-0.47793012  0.05564731  0.29885763  0.32472368 -1.97982015 -0.01286328]\n",
      "13 0.0686 0.1033 [-0.46352898  0.1589922   0.46148844  0.26012923 -2.06337773  0.15733373]\n",
      "14 0.0786 0.13 [-0.34339983  0.07781007  0.58066329  0.47399227 -2.18424118  0.13432401]\n",
      "15 0.0629 0.1133 [-0.38069499  0.09055969  0.31753873  0.28357402 -1.90589138  0.00573498]\n",
      "16 0.07 0.1 [-0.50982932  0.1075562   0.2575379   0.21998636 -2.02128755 -0.13548268]\n",
      "17 0.0671 0.1167 [-0.41855713  0.15169384  0.44088232  0.392244   -1.96391752  0.07018991]\n",
      "18 0.0557 0.1067 [-5.18517716e-01  1.76513197e-01  3.88946946e-01  3.59627537e-01\n",
      " -2.11472571e+00 -1.13139036e-03]\n",
      "19 0.0871 0.1033 [-0.43323027  0.21030635  0.07358895  0.27566035 -2.08041036 -0.16776726]\n",
      "20 0.0571 0.09 [-0.59397196  0.00975347  0.35675349  0.38065375 -2.2553171   0.03132593]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    theta_i = gradient_descent(X, Y, 0.01, 1500)\n",
    "    mc_error_train = misclassification_error(predict(X, theta_i, 0.5), Y)\n",
    "    mc_error_test = misclassification_error(predict(X_t, theta_i, 0.5), Y_t)\n",
    "    print(i+1, round(mc_error_train, 4), round(mc_error_test, 4), theta_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([-0.6088456, 0.08545795, 0.20969599, 0.45275746, -2.05835641, 0.09583985])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`confusion_matrix` function which returns confusion matrix given predicted labels and original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions, labels):\n",
    "    true_positives = np.logical_and(predictions, labels).sum()\n",
    "    false_positives = np.logical_and(predictions, np.logical_not(labels)).sum()\n",
    "    false_negatives = np.logical_and(np.logical_not(predictions), labels).sum()\n",
    "    true_negatives = np.logical_not(np.logical_or(predictions, labels)).sum()\n",
    "    return pd.DataFrame(data={'Predicted 0': [true_negatives, false_negatives], 'Predicted 1': [false_positives, true_positives]}, index=['Actual 0', 'Actual 1'])\n",
    "\n",
    "X = (features-features.mean())/features.std()\n",
    "X.insert(0, 'bias', 1)\n",
    "Y = labels.iloc[:, 0]\n",
    "CF = confusion_matrix(predict(X, theta, 0.5), Y)\n",
    "CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f1_score` function calculates F1 score given confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(confusion_matrix):\n",
    "    return (2*confusion_matrix[\"Predicted 1\"][\"Actual 1\"])/(2*confusion_matrix[\"Predicted 1\"][\"Actual 1\"]+confusion_matrix[\"Predicted 0\"][\"Actual 1\"]+confusion_matrix[\"Predicted 1\"][\"Actual 0\"])\n",
    "\n",
    "f1_score(CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same code developed in Question 1 to fit a logistic regression model to the dataset described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of Data Set 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains data for credit card fraud detection.\n",
    "\n",
    "-  **q2_data_matrix.csv:** This file contains a 100 × 5 data matrix. The 5 features and their corresponding ranges are described below:\n",
    " \n",
    "     1. **Age:** 18-100 years\n",
    "     2. **Transaction Amount:** \\$ 0-5000\n",
    "     3. **Total Monthly Transactions:** \\$ 0-50000\n",
    "     4. **Annual Income:** \\$ 30000-1000000\n",
    "     5. **Gender:** 0/1 (0 - Male, 1 - Female)\n",
    "     \n",
    "\n",
    "-  **q2_labels.csv:** This file contains a 1000 × 1 vector of 0/1 labels for whether the transaction is fraudulent or not.\n",
    "     <br><br>\n",
    "    -  0: The transaction is legitimate\n",
    "    -  1: The transaction is fraudulent\n",
    "    \n",
    "    \n",
    "    \n",
    "1. Report the confusion matrix and the F1 Score for this data set.\n",
    "2. Which data set gives better results better? Can you think of reasons as to why one data set gives better results than the other? (**Hint**: Think of assumptions behind the logistic regression model)\n",
    "3. Can you suggest improvements to the logistic regression model to make it perform better on the unfavorable data set?\n",
    "4. **Bonus Points!**: Implement your suggested improvement as a code and compare the performance of this with vanilla logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/q2_data_matrix.csv', header=None, names=['age', 'tram', 'tomotr', 'anin', 'gen'])\n",
    "labels = pd.read_csv('../data/q2_labels.csv', header=None, names=['fra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
